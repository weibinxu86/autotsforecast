{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e206d91c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path (for development)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "src_path = Path().absolute().parent / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "print(f\"âœ“ Path configured: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import autotsforecast components\n",
    "from autotsforecast import (\n",
    "    AutoForecaster,\n",
    "    VARForecaster,\n",
    "    LinearForecaster,\n",
    "    MovingAverageForecaster,\n",
    "    RandomForestForecaster,\n",
    "    XGBoostForecaster\n",
    ")\n",
    "from autotsforecast.hierarchical import HierarchicalReconciler\n",
    "from autotsforecast.interpretability import DriverAnalyzer\n",
    "\n",
    "print(\"âœ“ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094fb4c",
   "metadata": {},
   "source": [
    "## Part 1: Basic Forecasting with Single Models\n",
    "\n",
    "Let's start with forecasting sales for 3 regions using different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic sales data for 3 regions\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
    "\n",
    "# Create trend + seasonality + noise\n",
    "t = np.arange(200)\n",
    "trend = t * 0.5\n",
    "seasonality = 20 * np.sin(2 * np.pi * t / 30)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'North': 100 + trend + seasonality + np.random.normal(0, 10, 200),\n",
    "    'South': 120 + trend * 1.2 + seasonality + np.random.normal(0, 12, 200),\n",
    "    'East': 80 + trend * 0.8 + seasonality * 0.8 + np.random.normal(0, 8, 200)\n",
    "}, index=dates)\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(data.head())\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(12, 4))\n",
    "data.plot(ax=plt.gca())\n",
    "plt.title('Sales by Region')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "train_size = 150\n",
    "train_data = data.iloc[:train_size]\n",
    "test_data = data.iloc[train_size:]\n",
    "\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ce061",
   "metadata": {},
   "source": [
    "### 1.1 VAR (Vector AutoRegression) Model\n",
    "\n",
    "VAR models capture dependencies between multiple time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit VAR model\n",
    "var_model = VARForecaster(lags=7, horizon=50)\n",
    "var_model.fit(train_data)\n",
    "\n",
    "# Generate forecasts\n",
    "var_forecasts = var_model.predict()\n",
    "\n",
    "print(f\"VAR Forecast shape: {var_forecasts.shape}\")\n",
    "print(var_forecasts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6501e2",
   "metadata": {},
   "source": [
    "### 1.2 Random Forest Model\n",
    "\n",
    "Random Forest uses ensemble learning with lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea036d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit Random Forest model\n",
    "rf_model = RandomForestForecaster(n_lags=7, horizon=50, n_estimators=100)\n",
    "rf_model.fit(train_data)\n",
    "\n",
    "# Generate forecasts\n",
    "rf_forecasts = rf_model.predict()\n",
    "\n",
    "print(f\"Random Forest Forecast shape: {rf_forecasts.shape}\")\n",
    "print(rf_forecasts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc54f871",
   "metadata": {},
   "source": [
    "### 1.3 Compare Models Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68882268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs forecasts for North region\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.plot(train_data.index[-30:], train_data['North'][-30:], 'o-', label='Historical', linewidth=2)\n",
    "plt.plot(test_data.index, test_data['North'], 'o-', label='Actual', linewidth=2, color='green')\n",
    "plt.plot(test_data.index, var_forecasts['North'], '--', label='VAR Forecast', linewidth=2)\n",
    "plt.plot(test_data.index, rf_forecasts['North'], '--', label='RF Forecast', linewidth=2)\n",
    "\n",
    "plt.axvline(x=train_data.index[-1], color='red', linestyle='--', alpha=0.5, label='Train/Test Split')\n",
    "plt.title('Sales Forecasts: North Region')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE\n",
    "var_rmse = np.sqrt(np.mean((var_forecasts['North'].values - test_data['North'].values)**2))\n",
    "rf_rmse = np.sqrt(np.mean((rf_forecasts['North'].values - test_data['North'].values)**2))\n",
    "\n",
    "print(f\"\\nVAR Model RMSE: {var_rmse:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f9d07",
   "metadata": {},
   "source": [
    "## Part 2: AutoForecaster - Automatic Model Selection\n",
    "\n",
    "Instead of manually trying models, let **AutoForecaster** automatically select the best one using backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define candidate models to evaluate\n",
    "candidates = [\n",
    "    MovingAverageForecaster(window=5, horizon=50),\n",
    "    MovingAverageForecaster(window=7, horizon=50),\n",
    "    VARForecaster(lags=3, horizon=50),\n",
    "    VARForecaster(lags=5, horizon=50),\n",
    "    VARForecaster(lags=7, horizon=50),\n",
    "    LinearForecaster(n_lags=5, horizon=50),\n",
    "    RandomForestForecaster(n_lags=7, horizon=50, n_estimators=50),\n",
    "    XGBoostForecaster(n_lags=7, horizon=50)\n",
    "]\n",
    "\n",
    "# Create AutoForecaster\n",
    "auto = AutoForecaster(\n",
    "    candidate_models=candidates,\n",
    "    metric='rmse',\n",
    "    n_splits=3,\n",
    "    test_size=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit and select best model\n",
    "auto.fit(train_data)\n",
    "\n",
    "# Generate forecasts with best model\n",
    "auto_forecasts = auto.forecast()\n",
    "\n",
    "print(f\"\\nBest Model: {auto.best_model_name_}\")\n",
    "print(f\"Forecast shape: {auto_forecasts.shape}\")\n",
    "print(auto_forecasts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed performance summary\n",
    "summary = auto.get_summary()\n",
    "print(\"\\n\" + summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize backtesting results\n",
    "auto.plot_backtesting_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871714a",
   "metadata": {},
   "source": [
    "## Part 3: Using Covariates (External Variables)\n",
    "\n",
    "Improve forecasts by including external factors like promotions, holidays, or weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bdea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic covariates (e.g., marketing spend and temperature)\n",
    "covariates = pd.DataFrame({\n",
    "    'marketing_spend': 500 + 200 * np.sin(2 * np.pi * t / 60) + np.random.normal(0, 50, 200),\n",
    "    'temperature': 20 + 10 * np.sin(2 * np.pi * t / 365) + np.random.normal(0, 3, 200)\n",
    "}, index=dates)\n",
    "\n",
    "# Add covariates as features to the sales data\n",
    "sales_with_covariates = pd.concat([\n",
    "    data['North'] * (1 + covariates['marketing_spend'] / 5000),  # Marketing impact\n",
    "    data['South'] * (1 + covariates['temperature'] / 100),        # Temperature impact\n",
    "    data['East']\n",
    "], axis=1)\n",
    "sales_with_covariates.columns = ['North', 'South', 'East']\n",
    "\n",
    "# Split data\n",
    "train_y = sales_with_covariates.iloc[:train_size]\n",
    "test_y = sales_with_covariates.iloc[train_size:]\n",
    "train_X = covariates.iloc[:train_size]\n",
    "test_X = covariates.iloc[train_size:]\n",
    "\n",
    "print(f\"Target shape: {train_y.shape}\")\n",
    "print(f\"Covariates shape: {train_X.shape}\")\n",
    "print(f\"\\nCovariates preview:\")\n",
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model WITHOUT covariates\n",
    "model_no_cov = RandomForestForecaster(n_lags=7, horizon=50, n_estimators=100)\n",
    "model_no_cov.fit(train_y)\n",
    "pred_no_cov = model_no_cov.predict()\n",
    "\n",
    "# Train model WITH covariates\n",
    "model_with_cov = RandomForestForecaster(n_lags=7, horizon=50, n_estimators=100)\n",
    "model_with_cov.fit(train_y, train_X)\n",
    "pred_with_cov = model_with_cov.predict(test_X)\n",
    "\n",
    "# Compare performance\n",
    "rmse_no_cov = np.sqrt(np.mean((pred_no_cov.values - test_y.values)**2))\n",
    "rmse_with_cov = np.sqrt(np.mean((pred_with_cov.values - test_y.values)**2))\n",
    "\n",
    "print(f\"RMSE without covariates: {rmse_no_cov:.2f}\")\n",
    "print(f\"RMSE with covariates: {rmse_with_cov:.2f}\")\n",
    "print(f\"Improvement: {((rmse_no_cov - rmse_with_cov) / rmse_no_cov * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c88e5d",
   "metadata": {},
   "source": [
    "## Part 4: Hierarchical Reconciliation\n",
    "\n",
    "Ensure forecasts are coherent across aggregation levels (e.g., Total = North + South + East)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hierarchy structure\n",
    "# Total -> [North, South, East]\n",
    "hierarchy = {\n",
    "    'Total': ['North', 'South', 'East']\n",
    "}\n",
    "\n",
    "# Generate base forecasts (these may be incoherent)\n",
    "base_forecasts = auto_forecasts.copy()\n",
    "base_forecasts['Total'] = base_forecasts.sum(axis=1)\n",
    "\n",
    "print(\"Base Forecasts (potentially incoherent):\")\n",
    "print(base_forecasts.head())\n",
    "print(f\"\\nSum of regions: {base_forecasts[['North', 'South', 'East']].sum(axis=1).iloc[0]:.2f}\")\n",
    "print(f\"Total forecast: {base_forecasts['Total'].iloc[0]:.2f}\")\n",
    "print(f\"Difference: {abs(base_forecasts['Total'].iloc[0] - base_forecasts[['North', 'South', 'East']].sum(axis=1).iloc[0]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3514375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply hierarchical reconciliation\n",
    "reconciler = HierarchicalReconciler(hierarchy=hierarchy)\n",
    "\n",
    "# Method 1: Bottom-up (aggregate from lowest level)\n",
    "reconciled_bu = reconciler.reconcile(base_forecasts, method='bottom_up')\n",
    "print(\"Bottom-Up Reconciliation:\")\n",
    "print(reconciled_bu.head())\n",
    "\n",
    "# Method 2: MinTrace with shrinkage (optimal)\n",
    "reconciled_mint = reconciler.reconcile(base_forecasts, method='mint_shrink')\n",
    "print(\"\\nMinTrace Reconciliation:\")\n",
    "print(reconciled_mint.head())\n",
    "\n",
    "# Verify coherence\n",
    "print(f\"\\nCoherence check (Bottom-Up):\")\n",
    "print(f\"Sum of regions: {reconciled_bu[['North', 'South', 'East']].sum(axis=1).iloc[0]:.2f}\")\n",
    "print(f\"Total forecast: {reconciled_bu['Total'].iloc[0]:.2f}\")\n",
    "print(f\"Difference: {abs(reconciled_bu['Total'].iloc[0] - reconciled_bu[['North', 'South', 'East']].sum(axis=1).iloc[0]):.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b40c5f",
   "metadata": {},
   "source": [
    "## Part 5: Model Interpretability with SHAP\n",
    "\n",
    "Understand which features drive your forecasts using SHAP (SHapley Additive exPlanations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edacd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Random Forest model trained with covariates\n",
    "interpreter = DriverAnalyzer(model_with_cov)\n",
    "\n",
    "# Calculate SHAP values\n",
    "# Note: We need to recreate the feature matrix that the model uses\n",
    "from autotsforecast.utils.data import CovariatePreprocessor\n",
    "\n",
    "# Get training features the model actually used\n",
    "preprocessor = CovariatePreprocessor()\n",
    "X_processed = preprocessor.fit_transform(train_X)\n",
    "\n",
    "# Create lagged features\n",
    "n_lags = 7\n",
    "features = []\n",
    "for lag in range(1, n_lags + 1):\n",
    "    lagged = train_y.shift(lag)\n",
    "    lagged.columns = [f\"{col}_lag{lag}\" for col in train_y.columns]\n",
    "    features.append(lagged)\n",
    "features.append(X_processed)\n",
    "X_features = pd.concat(features, axis=1).dropna()\n",
    "\n",
    "print(f\"Feature matrix shape: {X_features.shape}\")\n",
    "print(f\"Features: {list(X_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "try:\n",
    "    shap_values = interpreter.calculate_shap_values(\n",
    "        X=X_features,\n",
    "        max_samples=100  # Use subset for speed\n",
    "    )\n",
    "    \n",
    "    print(\"âœ“ SHAP values calculated successfully!\")\n",
    "    print(f\"Number of outputs: {len(shap_values)}\")\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = interpreter.get_shap_feature_importance(shap_values)\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance.head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"SHAP calculation not available: {e}\")\n",
    "    print(\"Make sure SHAP is installed: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP summary for North region\n",
    "try:\n",
    "    interpreter.plot_shap_summary(\n",
    "        X=X_features,\n",
    "        shap_values_dict=shap_values,\n",
    "        target_name='North',\n",
    "        plot_type='bar'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Plotting not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82087f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered the complete **autotsforecast** workflow:\n",
    "\n",
    "### âœ… What You Learned\n",
    "\n",
    "1. **Basic Forecasting**: Used VAR, Random Forest, and other models\n",
    "2. **AutoForecaster**: Automated model selection with 8 candidate models\n",
    "3. **Covariates**: Improved accuracy by including external variables\n",
    "4. **Hierarchical Reconciliation**: Ensured forecast coherence across levels\n",
    "5. **SHAP Interpretability**: Understood feature importance in predictions\n",
    "\n",
    "### ðŸ“š Key Features\n",
    "\n",
    "- **Multiple Models**: VAR, Linear, Moving Average, Random Forest, XGBoost\n",
    "- **Automatic Selection**: Backtesting-based model comparison\n",
    "- **Covariate Support**: Include external variables for better forecasts\n",
    "- **Hierarchical Methods**: Bottom-up, Top-down, MinTrace (OLS, WLS, Shrinkage)\n",
    "- **Interpretability**: SHAP values for tree-based and linear models\n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "\n",
    "- Try with your own data\n",
    "- Experiment with different model parameters\n",
    "- Use custom hierarchies for your business structure\n",
    "- Install via pip (coming soon): `pip install autotsforecast`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
