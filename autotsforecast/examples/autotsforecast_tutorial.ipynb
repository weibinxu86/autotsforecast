{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e206d91c",
   "metadata": {},
   "source": [
    "# AutoTSForecast Tutorial\n",
    "\n",
    "Welcome to **AutoTSForecast** ‚Äî an automated time series forecasting library that follows the sklearn API pattern.\n",
    "\n",
    "## Quick Install\n",
    "\n",
    "```bash\n",
    "pip install autotsforecast\n",
    "```\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this tutorial, you'll learn how to:\n",
    "\n",
    "1. **AutoForecaster vs Individual Models** ‚Äî See how per-series model selection outperforms any single model\n",
    "2. **Hierarchical Reconciliation** ‚Äî Ensure coherent forecasts with region-level accuracy improvements\n",
    "3. **Interpretability** ‚Äî Understand which features drive your forecasts\n",
    "\n",
    "## Dataset: Retail Sales with Covariates\n",
    "\n",
    "We'll use a **synthetic retail sales dataset** with:\n",
    "- **3 time series**: `region_a`, `region_b`, `total` (hierarchical structure)\n",
    "- **2 covariates**: `temperature`, `promotion`\n",
    "- **Different patterns**: Region A responds strongly to promotions, Region B to temperature\n",
    "\n",
    "## Key Features Demonstrated\n",
    "\n",
    "- **AutoForecaster superiority**: Outperforms Prophet, ARIMA, XGBoost, and other models\n",
    "- **Per-Series Model Selection**: Each series independently selects its optimal model via CV\n",
    "- **No Data Leakage**: Holdout test set is never touched during model selection\n",
    "- **Region-Level Improvements**: Hierarchical reconciliation improves regional accuracy\n",
    "- **Interpretability**: Sensitivity analysis and SHAP values\n",
    "\n",
    "## Documentation Links\n",
    "\n",
    "- [Quick Start](../QUICKSTART.md) ‚Äî fastest overview\n",
    "- [API Reference](../API_REFERENCE.md) ‚Äî parameters and objects\n",
    "- [README](../README.md) ‚Äî package overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# AutoTSForecast imports\n",
    "from autotsforecast import AutoForecaster\n",
    "from autotsforecast.backtesting.validator import BacktestValidator\n",
    "from autotsforecast.hierarchical.reconciliation import HierarchicalReconciler\n",
    "from autotsforecast.interpretability.drivers import DriverAnalyzer\n",
    "\n",
    "# Model imports\n",
    "from autotsforecast.models.base import (\n",
    "    LinearForecaster, \n",
    "    MovingAverageForecaster,\n",
    "    VARForecaster\n",
    ")\n",
    "from autotsforecast.models.external import (\n",
    "    ARIMAForecaster, \n",
    "    ETSForecaster, \n",
    "    ProphetForecaster,\n",
    "    XGBoostForecaster,\n",
    "    RandomForestForecaster,\n",
    "    LSTMForecaster\n",
    ")\n",
    "\n",
    "# Optional: SHAP for interpretability\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Compatibility fixes for newer numpy versions\n",
    "if not hasattr(np, \"trapz\") and hasattr(np, \"trapezoid\"):\n",
    "    np.trapz = np.trapezoid\n",
    "if not hasattr(np, \"in1d\") and hasattr(np, \"isin\"):\n",
    "    np.in1d = np.isin\n",
    "\n",
    "# Helper functions\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
    "    return float(np.sqrt(np.mean((np.asarray(y_true) - np.asarray(y_pred))**2)))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n",
    "    return float(np.mean(np.abs((np.asarray(y_true) - np.asarray(y_pred)) / \n",
    "                                  (np.abs(np.asarray(y_true)) + 1e-9))) * 100)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample retail sales dataset with covariates\n",
    "np.random.seed(42)\n",
    "n_days = 240\n",
    "horizon = 14\n",
    "\n",
    "# Generate dates\n",
    "dates = pd.date_range('2023-01-01', periods=n_days, freq='D')\n",
    "time_step = np.arange(n_days)\n",
    "\n",
    "# Create covariates: temperature and promotions\n",
    "temperature = 20 + 8 * np.sin(2 * np.pi * time_step / 7) + np.random.normal(0, 0.8, n_days)\n",
    "promo = (np.random.rand(n_days) < 0.12).astype(int)\n",
    "promo[-horizon:] = (np.random.rand(horizon) < 0.45).astype(int)\n",
    "if promo[-horizon:].sum() == 0:\n",
    "    promo[-1] = 1\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'temperature': temperature,\n",
    "    'promotion': promo\n",
    "}, index=dates)\n",
    "\n",
    "# Generate sales data for two regions\n",
    "shared_noise = np.random.normal(0, 4.0, n_days)\n",
    "\n",
    "# Region A: Strong response to promotions\n",
    "region_a_sales = (\n",
    "    40 + 0.10 * time_step + 50.0 * X['promotion'].values + \n",
    "    1.6 * X['temperature'].values + shared_noise + np.random.normal(0, 0.8, n_days)\n",
    ")\n",
    "\n",
    "# Region B: Strong temperature effect\n",
    "region_b_sales = (\n",
    "    25 + 7.0 * np.sin(2 * np.pi * time_step / 30) + 2.0 * X['temperature'].values + \n",
    "    4.0 * X['promotion'].values - shared_noise + np.random.normal(0, 0.8, n_days)\n",
    ")\n",
    "\n",
    "# Total sales (hierarchical structure)\n",
    "total_sales = region_a_sales + region_b_sales\n",
    "\n",
    "y = pd.DataFrame({\n",
    "    'region_a': region_a_sales,\n",
    "    'region_b': region_b_sales,\n",
    "    'total': total_sales\n",
    "}, index=dates)\n",
    "\n",
    "# Train/test split\n",
    "y_train, y_test = y.iloc[:-horizon], y.iloc[-horizon:]\n",
    "X_train, X_test = X.iloc[:-horizon], X.iloc[-horizon:]\n",
    "\n",
    "print(f\"üìä Dataset Overview:\")\n",
    "print(f\"   Training: {y_train.index[0].date()} to {y_train.index[-1].date()} ({len(y_train)} days)\")\n",
    "print(f\"   Test: {y_test.index[0].date()} to {y_test.index[-1].date()} ({len(y_test)} days)\")\n",
    "print(f\"   Series: region_a, region_b, total\")\n",
    "print(f\"   Covariates: temperature, promotion\")\n",
    "\n",
    "# Visualize the data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "axes[0, 0].plot(y.index, y['region_a'], color='steelblue', linewidth=1.5)\n",
    "axes[0, 0].axvline(y_train.index[-1], color='red', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "axes[0, 0].set_title('Region A Sales', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Sales')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(y.index, y['region_b'], color='darkorange', linewidth=1.5)\n",
    "axes[0, 1].axvline(y_train.index[-1], color='red', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "axes[0, 1].set_title('Region B Sales', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Sales')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(y.index, y['total'], color='green', linewidth=1.5)\n",
    "axes[1, 0].axvline(y_train.index[-1], color='red', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "axes[1, 0].set_title('Total Sales', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Sales')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "ax2 = axes[1, 1]\n",
    "ax2.plot(X.index, X['temperature'], color='purple', alpha=0.7, linewidth=1.5)\n",
    "ax2.axvline(X_train.index[-1], color='red', linestyle='--', alpha=0.7)\n",
    "ax2.set_ylabel('Temperature (¬∞C)', color='purple')\n",
    "ax2.tick_params(axis='y', labelcolor='purple')\n",
    "ax2.set_title('Covariates', fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "ax2_right = ax2.twinx()\n",
    "promo_dates = X[X['promotion'] == 1].index\n",
    "ax2_right.scatter(promo_dates, X.loc[promo_dates, 'promotion'], color='red', alpha=0.6, s=30, marker='D')\n",
    "ax2_right.set_ylabel('Promotion', color='red')\n",
    "ax2_right.tick_params(axis='y', labelcolor='red')\n",
    "ax2_right.set_ylim(-0.1, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ce061",
   "metadata": {},
   "source": [
    "## Part 1: AutoForecaster vs Individual Models\n",
    "\n",
    "This section demonstrates **AutoTSForecast's key advantage**: automatic per-series model selection that outperforms using any single model for all series.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "When forecasting multiple time series, you have two choices:\n",
    "1. **Single Model**: Use the same model (e.g., Prophet) for all series\n",
    "2. **Per-Series Selection**: Let each series pick its optimal model via CV\n",
    "\n",
    "### AutoTSForecast Approach\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        TRAINING DATA ONLY                           ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    "‚îÇ  ‚îÇ  For EACH series: Run CV with ALL candidate models          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ  CV Fold 1:  [Train‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Val]                    ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ  CV Fold 2:  [Train‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Val]              ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ  CV Fold 3:  [Train‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ] [Val]        ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "‚îÇ                           ‚Üì                                         ‚îÇ\n",
    "‚îÇ         Select BEST model for EACH series (may differ!)             ‚îÇ\n",
    "‚îÇ                           ‚Üì                                         ‚îÇ\n",
    "‚îÇ         Retrain best model on FULL training data                    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                            ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                     HOLDOUT TEST SET                                ‚îÇ\n",
    "‚îÇ         (Never seen during training or model selection!)            ‚îÇ\n",
    "‚îÇ                           ‚Üì                                         ‚îÇ\n",
    "‚îÇ         Evaluate: AutoForecaster vs each individual model           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Available Models\n",
    "\n",
    "| Category | Models | Best For |\n",
    "|----------|---------|----------|\n",
    "| **Statistical** | Prophet, ARIMA, ETS | Trends & seasonality |\n",
    "| **Baselines** | Linear, Moving Average | Simple benchmarks |\n",
    "| **Multivariate** | VAR | Cross-series dependencies |\n",
    "| **Machine Learning** | XGBoost, Random Forest | Complex patterns |\n",
    "| **Deep Learning** | LSTM | Non-linear dynamics |\n",
    "\n",
    "Below we compare **AutoForecaster** (per-series selection) against each individual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7db1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   üîπ Training AutoForecaster on all \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(series_to_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m series...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m auto_forecaster = AutoForecaster(\n\u001b[32m     55\u001b[39m     candidate_models=candidate_models,\n\u001b[32m     56\u001b[39m     per_series_models=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Enable per-series model selection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     61\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mauto_forecaster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Fit on ALL series at once\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Display selected models\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   ‚úÖ Model selection complete:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\forecasting\\autotsforecast\\src\\autotsforecast\\forecaster.py:278\u001b[39m, in \u001b[36mAutoForecaster.fit\u001b[39m\u001b[34m(self, y, X)\u001b[39m\n\u001b[32m    275\u001b[39m     best_model.fit(y_single, X)\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m series_name, best_model, best_name, best_score, series_cv_results\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_one_series\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names_\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.best_models_ = {name: model \u001b[38;5;28;01mfor\u001b[39;00m name, model, _, _, _ \u001b[38;5;129;01min\u001b[39;00m results}\n\u001b[32m    283\u001b[39m \u001b[38;5;28mself\u001b[39m.best_model_names_ = {name: model_name \u001b[38;5;28;01mfor\u001b[39;00m name, _, model_name, _, _ \u001b[38;5;129;01min\u001b[39;00m results}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\forecasting\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Part 1: AutoForecaster vs Individual Models\n",
    "# This demonstrates AutoTSForecast's key advantage: per-series model selection\n",
    "print(\"üîÑ AutoForecaster vs Individual Models: Performance Comparison\")\n",
    "print(\"=\" * 75)\n",
    "print(\"\"\"\n",
    "üí° KEY TEST: Does AutoForecaster (per-series selection) outperform using\n",
    "   ANY single model for all time series?\n",
    "   \n",
    "   We'll compare AutoForecaster against: Prophet, ARIMA, ETS, XGBoost, \n",
    "   RandomForest, LSTM, and MovingAverage.\n",
    "   \n",
    "   Models will use COVARIATES (temperature, promotion) where supported.\n",
    "\"\"\")\n",
    "\n",
    "# All available models in the package\n",
    "all_models = {\n",
    "    'Prophet': lambda: ProphetForecaster(horizon=horizon),\n",
    "    'ARIMA': lambda: ARIMAForecaster(horizon=horizon),\n",
    "    'ETS': lambda: ETSForecaster(horizon=horizon),\n",
    "    'XGBoost': lambda: XGBoostForecaster(horizon=horizon, n_lags=14, n_estimators=100),\n",
    "    'RandomForest': lambda: RandomForestForecaster(horizon=horizon, n_lags=14, n_estimators=100),\n",
    "    'LSTM': lambda: LSTMForecaster(horizon=horizon, hidden_size=64, num_layers=2, epochs=50),\n",
    "    'MovingAvg': lambda: MovingAverageForecaster(horizon=horizon, window=7),\n",
    "}\n",
    "\n",
    "# Models that support covariates\n",
    "models_with_covariates = {'Prophet', 'ARIMA', 'XGBoost', 'RandomForest', 'LSTM'}\n",
    "\n",
    "series_to_test = ['region_a', 'region_b', 'total']\n",
    "\n",
    "print(f\"üìä Testing {len(series_to_test)} time series √ó {len(all_models)} models\")\n",
    "print(f\"   Series: {', '.join(series_to_test)}\")\n",
    "print(f\"   Models: {', '.join(all_models.keys())}\")\n",
    "print(f\"   With covariates: {', '.join(models_with_covariates)}\")\n",
    "\n",
    "# Step 1: Train AutoForecaster with per-series model selection\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"üìä STEP 1: Training AutoForecaster (Per-Series Model Selection)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Create candidate models for AutoForecaster\n",
    "candidate_models = [\n",
    "    ProphetForecaster(horizon=horizon),\n",
    "    ARIMAForecaster(horizon=horizon),\n",
    "    ETSForecaster(horizon=horizon),\n",
    "    XGBoostForecaster(horizon=horizon, n_lags=14, n_estimators=100),\n",
    "    RandomForestForecaster(horizon=horizon, n_lags=14, n_estimators=100),\n",
    "    LSTMForecaster(horizon=horizon, hidden_size=64, num_layers=2, epochs=50),\n",
    "    MovingAverageForecaster(horizon=horizon, window=7),\n",
    "]\n",
    "\n",
    "# Train AutoForecaster with per_series_models=True\n",
    "print(f\"\\n   üîπ Training AutoForecaster on all {len(series_to_test)} series...\")\n",
    "auto_forecaster = AutoForecaster(\n",
    "    candidate_models=candidate_models,\n",
    "    per_series_models=True,  # Enable per-series model selection\n",
    "    n_splits=3,\n",
    "    test_size=horizon,\n",
    "    metric='rmse',\n",
    "    verbose=False\n",
    ")\n",
    "auto_forecaster.fit(y_train, X=X_train)  # Fit on ALL series at once\n",
    "\n",
    "# Display selected models\n",
    "print(f\"\\n   ‚úÖ Model selection complete:\")\n",
    "for series_name in series_to_test:\n",
    "    best_model_name = type(auto_forecaster.best_models_[series_name]).__name__.replace('Forecaster', '')\n",
    "    print(f\"      ‚Ä¢ {series_name}: {best_model_name}\")\n",
    "\n",
    "print(\"\\n‚úÖ AutoForecaster training complete!\")\n",
    "\n",
    "# Step 2: Train individual models and compare on holdout test set\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"üìä STEP 2: Holdout Test Evaluation (AutoForecaster vs Individual Models)\")\n",
    "print(\"=\" * 75)\n",
    "print(\"   Training each individual model on full training data and testing on holdout...\")\n",
    "\n",
    "# Train and evaluate each individual model on holdout\n",
    "holdout_matrix = {}\n",
    "print(f\"\\n   {'Model':<15} {'region_a':<12} {'region_b':<12} {'total':<12} {'Avg RMSE':<12}\")\n",
    "print(f\"   {'-'*65}\")\n",
    "\n",
    "for model_name, model_factory in all_models.items():\n",
    "    holdout_matrix[model_name] = {}\n",
    "    row_rmses = []\n",
    "    \n",
    "    for series_name in series_to_test:\n",
    "        try:\n",
    "            model = model_factory()\n",
    "            # Use covariates if model supports them\n",
    "            if model_name in models_with_covariates:\n",
    "                model.fit(y_train[[series_name]], X=X_train)\n",
    "                predictions = model.predict(X=X_test)\n",
    "            else:\n",
    "                model.fit(y_train[[series_name]])\n",
    "                predictions = model.predict()\n",
    "            test_rmse = rmse(y_test[series_name], predictions[series_name])\n",
    "            holdout_matrix[model_name][series_name] = test_rmse\n",
    "            row_rmses.append(test_rmse)\n",
    "        except Exception as e:\n",
    "            holdout_matrix[model_name][series_name] = np.nan\n",
    "            row_rmses.append(np.nan)\n",
    "    \n",
    "    avg_rmse = np.nanmean(row_rmses) if row_rmses else np.nan\n",
    "    holdout_matrix[model_name]['Average'] = avg_rmse\n",
    "    \n",
    "    print(f\"   {model_name:<15} {holdout_matrix[model_name].get('region_a', np.nan):<12.2f} \"\n",
    "          f\"{holdout_matrix[model_name].get('region_b', np.nan):<12.2f} \"\n",
    "          f\"{holdout_matrix[model_name].get('total', np.nan):<12.2f} \"\n",
    "          f\"{avg_rmse:<12.2f}\")\n",
    "\n",
    "# Get AutoForecaster results (uses per-series selected models)\n",
    "print(f\"   {'-'*65}\")\n",
    "auto_forecasts = auto_forecaster.forecast(X=X_test)\n",
    "auto_rmses = []\n",
    "auto_str = f\"   ‚≠ê AutoForecaster \"\n",
    "for series_name in series_to_test:\n",
    "    test_rmse = rmse(y_test[series_name], auto_forecasts[series_name])\n",
    "    auto_rmses.append(test_rmse)\n",
    "    auto_str += f\" {test_rmse:<11.2f}\"\n",
    "auto_avg = np.mean(auto_rmses)\n",
    "auto_str += f\" {auto_avg:<12.2f}\"\n",
    "print(auto_str)\n",
    "\n",
    "# Calculate improvements vs each model\n",
    "print(f\"\\n\" + \"=\" * 75)\n",
    "print(\"üìä AUTOFORECASTER vs EACH INDIVIDUAL MODEL\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\n   {'Model':<15} {'Model Avg':<12} {'AutoForecaster':<15} {'Improvement':<15} {'Result':<10}\")\n",
    "print(f\"   {'-'*70}\")\n",
    "\n",
    "wins = 0\n",
    "ties = 0\n",
    "for model_name in all_models.keys():\n",
    "    model_avg = holdout_matrix[model_name]['Average']\n",
    "    improvement = model_avg - auto_avg\n",
    "    pct_improvement = 100 * improvement / model_avg if model_avg > 0 else 0\n",
    "    \n",
    "    if improvement > 0.01:\n",
    "        result = \"‚úÖ WINS\"\n",
    "        wins += 1\n",
    "    elif improvement < -0.01:\n",
    "        result = \"‚ùå LOSES\"\n",
    "    else:\n",
    "        result = \"‚Üî TIE\"\n",
    "        ties += 1\n",
    "    \n",
    "    print(f\"   {model_name:<15} {model_avg:<12.2f} {auto_avg:<15.2f} {improvement:>+6.2f} ({pct_improvement:>+5.1f}%) {result}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\" + \"=\" * 75)\n",
    "print(\"üèÜ FINAL VERDICT: AutoForecaster Performance\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Show which models were selected by AutoForecaster\n",
    "selected_models = {}\n",
    "for series_name in series_to_test:\n",
    "    selected_models[series_name] = type(auto_forecaster.best_models_[series_name]).__name__.replace('Forecaster', '')\n",
    "\n",
    "print(f\"\"\"\n",
    "   AutoForecaster (Per-Series Selection):\n",
    "   ‚Ä¢ region_a ‚Üí {selected_models['region_a']}\n",
    "   ‚Ä¢ region_b ‚Üí {selected_models['region_b']}\n",
    "   ‚Ä¢ total    ‚Üí {selected_models['total']}\n",
    "   \n",
    "   üìä Results vs Individual Models:\n",
    "   ‚Ä¢ Wins: {wins}/{len(all_models)} models\n",
    "   ‚Ä¢ Ties: {ties}/{len(all_models)} models\n",
    "   ‚Ä¢ Average RMSE: {auto_avg:.2f}\n",
    "      \n",
    "   üéØ This is the core value proposition of AutoTSForecast:\n",
    "      No need to manually test which model works best ‚Äî let the algorithm\n",
    "      find the optimal model for each series automatically!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21d9ba",
   "metadata": {},
   "source": [
    "## Part 2: Hierarchical Forecasting with Reconciliation\n",
    "\n",
    "When forecasting at multiple aggregation levels (e.g., regions + total), independent forecasts often violate the constraint:\n",
    "\n",
    "```\n",
    "forecast(total) ‚â† forecast(region_a) + forecast(region_b)\n",
    "```\n",
    "\n",
    "**Hierarchical reconciliation** adjusts forecasts to ensure coherence while **improving accuracy at the region level**.\n",
    "\n",
    "### Why Reconciliation Helps Regions\n",
    "\n",
    "OLS reconciliation doesn't just enforce coherence ‚Äî it **optimally redistributes forecast errors** across all levels. This often means:\n",
    "- Regions with higher uncertainty get adjusted more\n",
    "- Information from the total forecast helps improve regional accuracy\n",
    "- At least one region typically shows RMSE improvement\n",
    "\n",
    "### Methods Available\n",
    "- **OLS (Ordinary Least Squares)**: Optimally adjusts all levels to minimize squared errors\n",
    "- **Bottom-up**: Keeps bottom-level forecasts fixed, aggregates up\n",
    "\n",
    "We'll demonstrate that OLS reconciliation improves at least one region's forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Use base forecasts from Part 1 (AutoForecaster per-series selection)\n",
    "print(\"üìä Step 1: Prepare base forecasts for hierarchical reconciliation\")\n",
    "print(\"-\" * 75)\n",
    "print(\"\"\"\n",
    "üí° We'll use the AutoForecaster forecasts from Part 1 as our base forecasts.\n",
    "   These are the per-series optimized forecasts that we'll now reconcile.\n",
    "\"\"\")\n",
    "\n",
    "# Generate base forecasts using AutoForecaster (already trained in Part 1)\n",
    "base_forecasts = auto_forecaster.forecast(X=X_test)\n",
    "\n",
    "# Display which models were used\n",
    "for series_name in series_to_test:\n",
    "    model_name = type(auto_forecaster.best_models_[series_name]).__name__.replace('Forecaster', '')\n",
    "    print(f\"   {series_name}: Using {model_name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Base forecasts generated using AutoForecaster\")\n",
    "\n",
    "# Check coherence before reconciliation\n",
    "base_total = base_forecasts['total'].values\n",
    "base_sum = base_forecasts['region_a'].values + base_forecasts['region_b'].values\n",
    "\n",
    "coherence_error_base = np.abs(base_total - base_sum).mean()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Coherence check (before reconciliation):\")\n",
    "print(f\"   Mean |total - (region_a + region_b)|: {coherence_error_base:.2f}\")\n",
    "print(f\"   Forecasts do NOT add up correctly - this is normal for independent models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25681ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply hierarchical reconciliation\n",
    "print(\"üìä Step 2: Apply hierarchical reconciliation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Define hierarchy: total = region_a + region_b\n",
    "hierarchy = {'total': ['region_a', 'region_b']}\n",
    "\n",
    "# Use OLS reconciliation (Ordinary Least Squares)\n",
    "reconciler = HierarchicalReconciler(forecasts=base_forecasts, hierarchy=hierarchy)\n",
    "reconciler.reconcile(method='ols')\n",
    "reconciled_forecasts = reconciler.reconciled_forecasts\n",
    "\n",
    "print(f\"‚úÖ Applied OLS reconciliation\")\n",
    "\n",
    "# Check coherence after reconciliation\n",
    "reconciled_total = reconciled_forecasts['total'].values\n",
    "reconciled_sum = reconciled_forecasts['region_a'].values + reconciled_forecasts['region_b'].values\n",
    "coherence_error_reconciled = np.abs(reconciled_total - reconciled_sum).mean()\n",
    "\n",
    "print(f\"\\n‚úÖ Coherence check (after reconciliation):\")\n",
    "print(f\"   Mean |total - (region_a + region_b)|: {coherence_error_reconciled:.10f}\")\n",
    "print(f\"   Forecasts now add up correctly!\")\n",
    "\n",
    "# Accuracy comparison - Focus on REGION-LEVEL improvements\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä ACCURACY COMPARISON: Focus on Region-Level Improvements\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n   {'Series':<12} {'Base RMSE':<12} {'Reconciled':<12} {'Change':<12} {'Result':<15}\")\n",
    "print(f\"   {'-'*60}\")\n",
    "\n",
    "results = {}\n",
    "for col in ['region_a', 'region_b', 'total']:\n",
    "    base_rmse_val = rmse(y_test[col], base_forecasts[col])\n",
    "    recon_rmse = rmse(y_test[col], reconciled_forecasts[col])\n",
    "    change = 100 * (recon_rmse - base_rmse_val) / base_rmse_val\n",
    "    results[col] = {'base': base_rmse_val, 'reconciled': recon_rmse, 'change': change}\n",
    "    result_str = \"‚úÖ IMPROVED\" if change < 0 else (\"‚Üî Same\" if change == 0 else \"Trade-off\")\n",
    "    print(f\"   {col:<12} {base_rmse_val:<12.2f} {recon_rmse:<12.2f} {change:>+6.1f}%     {result_str}\")\n",
    "\n",
    "# Highlight region-level improvements\n",
    "improved_regions = [k for k in ['region_a', 'region_b'] if results[k]['change'] < 0]\n",
    "improved_all = [k for k, v in results.items() if v['change'] < 0]\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"üìñ REGION-LEVEL INTERPRETATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if improved_regions:\n",
    "    print(f\"\\nüéØ REGION IMPROVEMENTS (Key Benefit of OLS Reconciliation):\")\n",
    "    for region in improved_regions:\n",
    "        print(f\"   ‚úÖ {region}: RMSE reduced by {abs(results[region]['change']):.1f}%\")\n",
    "        print(f\"      Base: {results[region]['base']:.2f} ‚Üí Reconciled: {results[region]['reconciled']:.2f}\")\n",
    "    \n",
    "    print(f\"\"\"\n",
    "   üí° WHY REGIONS IMPROVE:\n",
    "      OLS reconciliation uses information from ALL levels to adjust forecasts.\n",
    "      When the total forecast is more accurate than individual regions,\n",
    "      OLS \"borrows strength\" from the total to improve regional estimates.\n",
    "\"\"\")\n",
    "else:\n",
    "    print(f\"\\n   Note: In this run, regions traded accuracy for coherence.\")\n",
    "    print(f\"   Re-run with different data to see region improvements.\")\n",
    "\n",
    "if improved_all:\n",
    "    print(f\"\\nüìä All improved series: {', '.join(improved_all)}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üí° Key Takeaways:\n",
    "   1. COHERENCE: Forecasts now satisfy total = region_a + region_b\n",
    "   2. REGION ACCURACY: OLS can improve region-level forecasts (not just total)\n",
    "   3. BUSINESS VALUE: Coherent + accurate regional forecasts for:\n",
    "      - Inventory allocation across warehouses\n",
    "      - Regional sales targets that sum to company total\n",
    "      - Consistent budgeting across organizational levels\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize base vs reconciled forecasts\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "series_names = ['region_a', 'region_b', 'total']\n",
    "colors = ['steelblue', 'darkorange', 'green']\n",
    "\n",
    "for idx, (series, color) in enumerate(zip(series_names, colors)):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(y_test.index, y_test[series], label='Actual', color='black', linewidth=2, marker='o', markersize=4)\n",
    "    ax.plot(base_forecasts.index, base_forecasts[series], label='Base', color=color, \n",
    "            linewidth=2, linestyle='--', alpha=0.6)\n",
    "    ax.plot(reconciled_forecasts.index, reconciled_forecasts[series], label='Reconciled', \n",
    "            color='red', linewidth=2, linestyle='-.')\n",
    "    \n",
    "    base_err = rmse(y_test[series], base_forecasts[series])\n",
    "    recon_err = rmse(y_test[series], reconciled_forecasts[series])\n",
    "    ax.set_title(f'{series.replace(\"_\", \" \").title()}\\nRMSE: {base_err:.1f} ‚Üí {recon_err:.1f}', fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Sales')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520220f",
   "metadata": {},
   "source": [
    "## Part 3: Interpretability ‚Äî Understanding Forecast Drivers\n",
    "\n",
    "Understanding *why* a model makes certain predictions is crucial for:\n",
    "- **Building trust**: Stakeholders need to understand the model\n",
    "- **Debugging**: Identify when the model is using spurious correlations\n",
    "- **Business insights**: Learn which factors truly drive your metrics\n",
    "\n",
    "The `DriverAnalyzer` provides:\n",
    "1. **Sensitivity analysis**: Perturbs features and measures prediction change (works for all models)\n",
    "2. **SHAP values**: Game-theoretic attribution for tree-based models (XGBoost, RandomForest)\n",
    "\n",
    "We'll analyze feature importance for **all three series** to see how temperature and promotion affect each differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a776993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze forecast drivers for ALL SERIES using trained AutoForecaster models\n",
    "print(f\"üìä Sensitivity Analysis: Feature Importance for All Series\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "üí° We'll use the trained AutoForecaster models from Part 1 for each series.\n",
    "   DriverAnalyzer will automatically select the best interpretability method \n",
    "   for the underlying best model chosen by AutoForecaster.\n",
    "\"\"\")\n",
    "\n",
    "# Store results for all series\n",
    "sensitivity_results = {}\n",
    "\n",
    "for series_name in ['region_a', 'region_b', 'total']:\n",
    "    print(f\"\\nüîπ Series: {series_name}\")\n",
    "    \n",
    "    # Use the best model selected by AutoForecaster for this series\n",
    "    best_model = auto_forecaster.best_models_[series_name]\n",
    "    best_model_name = type(best_model).__name__.replace('Forecaster', '')\n",
    "    print(f\"   Selected Model: {best_model_name}\")\n",
    "    \n",
    "    # Create DriverAnalyzer with the best model\n",
    "    analyzer = DriverAnalyzer(\n",
    "        model=best_model,\n",
    "        feature_names=['temperature', 'promotion']\n",
    "    )\n",
    "    \n",
    "    # Let DriverAnalyzer automatically select the best interpretation method\n",
    "    # It will try SHAP for tree-based models, otherwise fall back to sensitivity\n",
    "    try:\n",
    "        importance_df = analyzer.calculate_feature_importance(X_test, y_test[[series_name]])\n",
    "        method_used = \"SHAP/Permutation\" if hasattr(best_model, 'feature_importances_') else \"Sensitivity\"\n",
    "    except Exception as e:\n",
    "        # Fallback to sensitivity analysis if automatic selection fails\n",
    "        importance_df = analyzer.calculate_feature_importance(X_test, y_test[[series_name]], method='sensitivity')\n",
    "        method_used = \"Sensitivity\"\n",
    "    \n",
    "    print(f\"   Method: {method_used}\")\n",
    "    \n",
    "    # Extract importance values\n",
    "    temp_sens = float(importance_df.loc['temperature'].mean())\n",
    "    promo_sens = float(importance_df.loc['promotion'].mean())\n",
    "    sensitivity_results[series_name] = {'temperature': temp_sens, 'promotion': promo_sens}\n",
    "    \n",
    "    print(f\"   temperature    : {temp_sens:.4f}\")\n",
    "    print(f\"   promotion      : {promo_sens:.4f}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä SUMMARY: Feature Impact Across All Series\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n   {'Series':<15} {'Temperature':<15} {'Promotion':<15} {'Dominant Driver':<20}\")\n",
    "print(f\"   {'-'*65}\")\n",
    "for series_name in ['region_a', 'region_b', 'total']:\n",
    "    temp = sensitivity_results[series_name]['temperature']\n",
    "    promo = sensitivity_results[series_name]['promotion']\n",
    "    dominant = 'Promotion' if promo > temp else 'Temperature'\n",
    "    print(f\"   {series_name:<15} {temp:<15.4f} {promo:<15.4f} {dominant:<20}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üìñ INTERPRETATION:\n",
    "   ‚Ä¢ Feature importance shows how much predictions change when each feature \n",
    "     is perturbed (sensitivity) or attributed (SHAP/permutation)\n",
    "   ‚Ä¢ Higher values = model predictions are more sensitive to that feature\n",
    "   \n",
    "   Expected based on data generation:\n",
    "      ‚Ä¢ region_a: +50 per promotion, +1.6 per ¬∞C ‚Üí Promotion dominant ‚úì\n",
    "      ‚Ä¢ region_b: +4 per promotion, +2.0 per ¬∞C ‚Üí Temperature more important\n",
    "      ‚Ä¢ total: Sum of both ‚Üí Mixed effects\n",
    "      \n",
    "   üí° AutoForecaster automatically selected the best model for each series,\n",
    "      and DriverAnalyzer automatically selected the best interpretation method\n",
    "      for each model type (SHAP for tree-based, sensitivity for others).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "if importance_df is not None:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    # Calculate mean importance across targets\n",
    "    mean_importance = importance_df.mean(axis=1)\n",
    "    \n",
    "    colors = ['steelblue', 'darkorange']\n",
    "    bars = plt.barh(mean_importance.index, mean_importance.values, color=colors)\n",
    "    \n",
    "    plt.xlabel('Importance Score (higher = more important)')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance Analysis', fontweight='bold')\n",
    "    plt.grid(alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"üìñ INTERPRETATION:\")\n",
    "    print(f\"   Higher values indicate features that cause larger prediction errors when shuffled.\")\n",
    "    print(f\"   This means the model relies more heavily on these features for accurate forecasts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa946c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed SHAP Analysis Example (Region A)\n",
    "print(\"üîç Detailed Interpretability Analysis (Region A)\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "üí° We'll demonstrate advanced interpretability using Region A's model.\n",
    "   If the AutoForecaster selected a tree-based model, we'll show SHAP values.\n",
    "   Otherwise, we'll demonstrate sensitivity analysis in detail.\n",
    "\"\"\")\n",
    "\n",
    "# Get the best model for region_a from AutoForecaster\n",
    "region_a_model = auto_forecaster.best_models_['region_a']\n",
    "region_a_model_name = type(region_a_model).__name__.replace('Forecaster', '')\n",
    "\n",
    "print(f\"\\nüìä Region A Model: {region_a_model_name}\")\n",
    "\n",
    "# Generate predictions\n",
    "region_a_forecast = auto_forecaster.forecast(X=X_test)\n",
    "region_a_rmse = rmse(y_test['region_a'], region_a_forecast['region_a'])\n",
    "print(f\"   Holdout RMSE: {region_a_rmse:.2f}\")\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = DriverAnalyzer(\n",
    "    model=region_a_model,\n",
    "    feature_names=['temperature', 'promotion']\n",
    ")\n",
    "\n",
    "# Always show sensitivity analysis (works for all models)\n",
    "print(f\"\\nüìä Sensitivity Analysis:\")\n",
    "sensitivity = analyzer.calculate_feature_importance(X_test, y_test[['region_a']], method='sensitivity')\n",
    "\n",
    "temp_sens = float(sensitivity.loc['temperature'].mean())\n",
    "promo_sens = float(sensitivity.loc['promotion'].mean())\n",
    "\n",
    "print(f\"   temperature    : {temp_sens:.4f}\")\n",
    "print(f\"   promotion      : {promo_sens:.4f}\")\n",
    "\n",
    "print(f\"\\nüìñ INTERPRETATION:\")\n",
    "if promo_sens > temp_sens:\n",
    "    print(f\"   ‚Ä¢ Promotion has ~{promo_sens/temp_sens:.1f}x more impact than temperature\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Temperature has ~{temp_sens/promo_sens:.1f}x more impact than promotion\")\n",
    "print(f\"   ‚Ä¢ This matches our data: Region A has +50 sales per promotion, +1.6 per ¬∞C\")\n",
    "\n",
    "# Try SHAP if model is tree-based and SHAP is available\n",
    "is_tree_based = region_a_model_name in ['XGBoost', 'RandomForest']\n",
    "\n",
    "if SHAP_AVAILABLE and is_tree_based:\n",
    "    try:\n",
    "        print(f\"\\nüìä SHAP Values (game-theoretic feature attribution):\")\n",
    "        shap_values = analyzer.calculate_shap_values(X_train, y_train[['region_a']])\n",
    "        shap_importance_df = analyzer.get_shap_feature_importance(shap_values)\n",
    "        \n",
    "        # Display SHAP importance\n",
    "        print(f\"   SHAP feature importance (mean |SHAP|):\")\n",
    "        for feature in shap_importance_df.index:\n",
    "            imp_val = float(shap_importance_df.loc[feature].mean())\n",
    "            print(f\"   {feature:<15}: {imp_val:.4f}\")\n",
    "            \n",
    "        print(f\"\\n   üí° SHAP values provide theoretically grounded attribution based on\")\n",
    "        print(f\"      Shapley values from cooperative game theory. They consider\")\n",
    "        print(f\"      feature interactions and provide consistent, accurate attribution.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n   ‚ö†Ô∏è SHAP calculation issue: {str(e)[:80]}...\")\n",
    "        print(f\"   Sensitivity analysis above provides reliable feature importance.\")\n",
    "        \n",
    "elif is_tree_based and not SHAP_AVAILABLE:\n",
    "    print(f\"\\nüí° Install SHAP for advanced attribution: pip install shap\")\n",
    "    print(f\"   SHAP works with tree-based models (XGBoost, RandomForest)\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nüí° SHAP analysis is available for tree-based models (XGBoost, RandomForest).\")\n",
    "    print(f\"   Current model ({region_a_model_name}) uses sensitivity analysis.\")\n",
    "    print(f\"   Sensitivity analysis perturbs features and measures prediction changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc149c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned how to use AutoTSForecast for:\n",
    "\n",
    "1. **AutoForecaster vs Individual Models**\n",
    "   - AutoForecaster outperforms using any single model for all series\n",
    "   - Per-series model selection via CV on training data only (no data leakage)\n",
    "   - Different series automatically select their optimal models\n",
    "\n",
    "2. **Hierarchical Reconciliation with Region-Level Improvements**\n",
    "   - Ensure forecasts are coherent: `total = region_a + region_b`\n",
    "   - OLS reconciliation can improve region-level accuracy (not just total)\n",
    "   - Trade-off: coherence + potential regional improvements\n",
    "\n",
    "3. **Interpretability**\n",
    "   - Sensitivity analysis: feature impact on predictions\n",
    "   - SHAP values for tree-based models (XGBoost, RandomForest)\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "### AutoForecaster (Per-Series Model Selection)\n",
    "```python\n",
    "from autotsforecast import AutoForecaster\n",
    "from autotsforecast.models.external import ProphetForecaster, XGBoostForecaster\n",
    "\n",
    "# Each series independently selects its best model via CV\n",
    "forecaster = AutoForecaster(\n",
    "    candidate_models=[ProphetForecaster(horizon=14), XGBoostForecaster(horizon=14)],\n",
    "    n_splits=3,\n",
    "    test_size=14,\n",
    "    metric='rmse'\n",
    ")\n",
    "forecaster.fit(y_train)  # Multivariate: DataFrame with multiple columns\n",
    "forecast = forecaster.forecast()\n",
    "```\n",
    "\n",
    "### Hierarchical Reconciliation\n",
    "```python\n",
    "from autotsforecast.hierarchical.reconciliation import HierarchicalReconciler\n",
    "\n",
    "reconciler = HierarchicalReconciler(forecasts=base_forecasts, hierarchy={'total': ['region_a', 'region_b']})\n",
    "reconciler.reconcile(method='ols')\n",
    "coherent_forecasts = reconciler.reconciled_forecasts\n",
    "```\n",
    "\n",
    "### Backtesting Individual Models\n",
    "```python\n",
    "from autotsforecast.backtesting.validator import BacktestValidator\n",
    "\n",
    "validator = BacktestValidator(model=ProphetForecaster(horizon=14), n_splits=5, test_size=14)\n",
    "validator.run(y_train)\n",
    "results = validator.get_fold_results()  # DataFrame with rmse, mape per fold\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **[API Reference](../API_REFERENCE.md)** ‚Äî Detailed parameter documentation\n",
    "- **[Quick Start](../QUICKSTART.md)** ‚Äî Condensed overview\n",
    "- **[Technical Documentation](../TECHNICAL_DOCUMENTATION.md)** ‚Äî Advanced topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
